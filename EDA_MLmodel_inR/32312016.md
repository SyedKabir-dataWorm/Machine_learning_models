---
title: "Exploratory Data Analysis and Model Building"
author: "Syed Kabir"
date: "1/21/2022"
output:
  html_document:
    keep_md : true
    toc: true # table of content true
    toc_depth: 3  # upto three depths of headings 
    number_sections: true  ## if you want number sections at each table header
    theme: united  # many options for theme, this one is my favorite.
---




```r
# installing all required packages
#install.packages('plyr', repos="http://cran.rstudio.com/")
#install.packages('ggplot2', repos="http://cran.rstudio.com/")
#install.packages('psych')
#install.packages('gridExtra')
#install.packages('ISLR')
#install.packages('MASS')
#install.packages('caret', repos="http://cran.rstudio.com/")
#install.packages('car')
#install.packages('psych')
```



```r
library(psych)
library(gridExtra) 
library(ggplot2)
```

```
## 
## Attaching package: 'ggplot2'
```

```
## The following objects are masked from 'package:psych':
## 
##     %+%, alpha
```

```r
library(car)
```

```
## Loading required package: carData
```

```
## 
## Attaching package: 'car'
```

```
## The following object is masked from 'package:psych':
## 
##     logit
```

```r
library(caret)
```

```
## Loading required package: lattice
```

```r
library(tidyverse) 
```

```
## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --
```

```
## v tibble  3.1.2     v dplyr   1.0.6
## v tidyr   1.1.3     v stringr 1.4.0
## v readr   1.4.0     v forcats 0.5.1
## v purrr   0.3.4
```

```
## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x ggplot2::%+%()   masks psych::%+%()
## x ggplot2::alpha() masks psych::alpha()
## x dplyr::combine() masks gridExtra::combine()
## x dplyr::filter()  masks stats::filter()
## x dplyr::lag()     masks stats::lag()
## x purrr::lift()    masks caret::lift()
## x dplyr::recode()  masks car::recode()
## x purrr::some()    masks car::some()
```

```r
library(magrittr)
```

```
## 
## Attaching package: 'magrittr'
```

```
## The following object is masked from 'package:purrr':
## 
##     set_names
```

```
## The following object is masked from 'package:tidyr':
## 
##     extract
```

```r
library(MASS)
```

```
## 
## Attaching package: 'MASS'
```

```
## The following object is masked from 'package:dplyr':
## 
##     select
```

```r
library(psych)
```

# Introduction:
This assignment is to perform exploratory data analysis on insurance data followed by appropriate modelling to predict whether a customer of a insurance company will stay or leave. Sixteen distinguishing factors are given in the data-set in understanding the customer churn. Two data-sets are given:

  a) trainSet.csv which contains 27126 observations

  b) testSet.csv which contains 6782 observations

  So, trainSet data will be used to perform exploratory analysis and training the model. Two distinguished models will be build-up using training data. On the other hand, testSet.csv will be used for identifying model accuracy and selecting better model.


```r
insurance1 <- read.csv('trainSet.csv', header = TRUE, sep = ',')
testset <- read.csv('testSet.csv', header = TRUE, sep = ',')
```


```r
head(insurance1)
```

```
##    feature_0  feature_1  feature_2   feature_3   feature_4  feature_5
## 1  1.5127910 -0.2434605  0.1434182  2.01858846  0.07622994 -0.4114531
## 2 -1.5007763 -0.2125875  1.2248391 -0.15984112 -0.56935064 -0.4114531
## 3  0.9477471  0.5812426 -0.3372133  0.77987360 -0.56935064 -0.4114531
## 4 -0.8415585 -0.2217837  0.5038918 -0.37729577  0.39902023 -0.4114531
## 5 -0.5590365 -0.5922597 -1.1783185 -0.41612696 -0.56935064 -0.4114531
## 6  0.9477471 -0.4654833 -0.5775291  0.08867847 -0.24656035  2.2551433
##    feature_6 feature_7 feature_8 feature_9 feature_10 feature_11 feature_12
## 1 -0.2519404         1         1         1          0          1          0
## 2 -0.2519404         8         2         1          0          0          0
## 3 -0.2519404         0         2         1          0          0          0
## 4 -0.2519404         9         1         1          0          0          0
## 5 -0.2519404         1         2         1          0          1          0
## 6  2.3528870         4         2         2          1          1          0
##   feature_13 feature_14 feature_15 labels
## 1          0          0          3      0
## 2          0          8          3      0
## 3          2          8          3      0
## 4          0          1          3      0
## 5          0          8          3      0
## 6          0          8          0      0
```

```r
# Now, let's check the number of variables, rows, variable names and their types
str(insurance1)
```

```
## 'data.frame':	27126 obs. of  17 variables:
##  $ feature_0 : num  1.513 -1.501 0.948 -0.842 -0.559 ...
##  $ feature_1 : num  -0.243 -0.213 0.581 -0.222 -0.592 ...
##  $ feature_2 : num  0.143 1.225 -0.337 0.504 -1.178 ...
##  $ feature_3 : num  2.019 -0.16 0.78 -0.377 -0.416 ...
##  $ feature_4 : num  0.0762 -0.5694 -0.5694 0.399 -0.5694 ...
##  $ feature_5 : num  -0.411 -0.411 -0.411 -0.411 -0.411 ...
##  $ feature_6 : num  -0.252 -0.252 -0.252 -0.252 -0.252 ...
##  $ feature_7 : int  1 8 0 9 1 4 7 6 6 9 ...
##  $ feature_8 : int  1 2 2 1 2 2 1 1 1 1 ...
##  $ feature_9 : int  1 1 1 1 1 2 1 2 1 3 ...
##  $ feature_10: int  0 0 0 0 0 1 0 0 0 0 ...
##  $ feature_11: int  1 0 0 0 1 1 0 1 1 1 ...
##  $ feature_12: int  0 0 0 0 0 0 0 1 1 0 ...
##  $ feature_13: int  0 0 2 0 0 0 0 2 0 0 ...
##  $ feature_14: int  0 8 8 1 8 8 1 6 5 9 ...
##  $ feature_15: int  3 3 3 3 3 0 3 3 3 3 ...
##  $ labels    : int  0 0 0 0 0 0 0 0 0 0 ...
```
The structure of the training data set shows that:

feature_o, feature_1, feature_2, feature_3,feature_4, feature_5 and feature_6 are continuous type numerical variables.

feature_7, feature_8, feature_9, feature_10,feature_11, feature_12, feature_13, feature_14 and feature_15 are discrete type variables.


```r
# Let's check how many unique values are avilable for each variable:
sapply(insurance1, function(x) length(unique(x)))
```

```
##  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6 
##         77       5901         31       1403         46        499         35 
##  feature_7  feature_8  feature_9 feature_10 feature_11 feature_12 feature_13 
##         12          3          4          2          2          2          3 
## feature_14 feature_15     labels 
##         12          4          2
```
So, feature_1 has highest highest number of unique values.
feature_10, feature_11, feature_12, labels are of binary.
feature_8 and feature_13 have three unique values : 0,1 and 2
feature_9 and feature_15 have four unique values : 0,1,2 and 3

# EDA:


```r
summary(insurance1)
```

```
##    feature_0           feature_1           feature_2        
##  Min.   :-2.159994   Min.   :-3.081149   Min.   :-1.779108  
##  1st Qu.:-0.747384   1st Qu.:-0.422458   1st Qu.:-0.938003  
##  Median :-0.182341   Median :-0.296996   Median : 0.023260  
##  Mean   :-0.004908   Mean   : 0.001337   Mean   : 0.003681  
##  3rd Qu.: 0.665225   3rd Qu.: 0.023886   3rd Qu.: 0.624050  
##  Max.   : 5.091402   Max.   :26.222907   Max.   : 1.825629  
##    feature_3           feature_4           feature_5        
##  Min.   :-1.002478   Min.   :-0.569351   Min.   :-0.411453  
##  1st Qu.:-0.602517   1st Qu.:-0.569351   1st Qu.:-0.411453  
##  Median :-0.307400   Median :-0.246560   Median :-0.411453  
##  Mean   :-0.002433   Mean   :-0.000047   Mean   :-0.002946  
##  3rd Qu.: 0.232354   3rd Qu.: 0.076230   3rd Qu.:-0.411453  
##  Max.   :18.094700   Max.   :19.443647   Max.   : 8.127648  
##    feature_6           feature_7        feature_8      feature_9    
##  Min.   :-0.251940   Min.   : 0.000   Min.   :0.00   Min.   :0.000  
##  1st Qu.:-0.251940   1st Qu.: 1.000   1st Qu.:1.00   1st Qu.:1.000  
##  Median :-0.251940   Median : 4.000   Median :1.00   Median :1.000  
##  Mean   :-0.009104   Mean   : 4.336   Mean   :1.17   Mean   :1.226  
##  3rd Qu.:-0.251940   3rd Qu.: 7.000   3rd Qu.:2.00   3rd Qu.:2.000  
##  Max.   :23.625644   Max.   :11.000   Max.   :2.00   Max.   :3.000  
##    feature_10        feature_11       feature_12      feature_13    
##  Min.   :0.00000   Min.   :0.0000   Min.   :0.000   Min.   :0.0000  
##  1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000  
##  Median :0.00000   Median :1.0000   Median :0.000   Median :0.0000  
##  Mean   :0.01788   Mean   :0.5522   Mean   :0.159   Mean   :0.6365  
##  3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.000   3rd Qu.:2.0000  
##  Max.   :1.00000   Max.   :1.0000   Max.   :1.000   Max.   :2.0000  
##    feature_14       feature_15        labels      
##  Min.   : 0.000   Min.   :0.000   Min.   :0.0000  
##  1st Qu.: 3.000   1st Qu.:3.000   1st Qu.:0.0000  
##  Median : 6.000   Median :3.000   Median :0.0000  
##  Mean   : 5.513   Mean   :2.562   Mean   :0.1173  
##  3rd Qu.: 8.000   3rd Qu.:3.000   3rd Qu.:0.0000  
##  Max.   :11.000   Max.   :3.000   Max.   :1.0000
```

```r
round(describe(insurance1), 3)
```

```
##            vars     n  mean   sd median trimmed  mad   min   max range  skew
## feature_0     1 27126  0.00 1.00  -0.18   -0.07 0.98 -2.16  5.09  7.25  0.68
## feature_1     2 27126  0.00 0.99  -0.30   -0.19 0.22 -3.08 26.22 29.30  7.50
## feature_2     3 27126  0.00 1.00   0.02   -0.01 1.25 -1.78  1.83  3.60  0.09
## feature_3     4 27126  0.00 1.00  -0.31   -0.19 0.53 -1.00 18.09 19.10  3.16
## feature_4     5 27126  0.00 1.01  -0.25   -0.21 0.48 -0.57 19.44 20.01  5.10
## feature_5     6 27126  0.00 1.00  -0.41   -0.28 0.00 -0.41  8.13  8.54  2.64
## feature_6     7 27126 -0.01 0.80  -0.25   -0.20 0.00 -0.25 23.63 23.88  7.36
## feature_7     8 27126  4.34 3.27   4.00    4.24 4.45  0.00 11.00 11.00  0.27
## feature_8     9 27126  1.17 0.60   1.00    1.21 0.00  0.00  2.00  2.00 -0.10
## feature_9    10 27126  1.23 0.75   1.00    1.23 0.00  0.00  3.00  3.00  0.19
## feature_10   11 27126  0.02 0.13   0.00    0.00 0.00  0.00  1.00  1.00  7.28
## feature_11   12 27126  0.55 0.50   1.00    0.56 0.00  0.00  1.00  1.00 -0.21
## feature_12   13 27126  0.16 0.37   0.00    0.07 0.00  0.00  1.00  1.00  1.86
## feature_13   14 27126  0.64 0.90   0.00    0.55 0.00  0.00  2.00  2.00  0.78
## feature_14   15 27126  5.51 3.00   6.00    5.67 2.96  0.00 11.00 11.00 -0.47
## feature_15   16 27126  2.56 0.99   3.00    2.83 0.00  0.00  3.00  3.00 -1.98
## labels       17 27126  0.12 0.32   0.00    0.02 0.00  0.00  1.00  1.00  2.38
##            kurtosis   se
## feature_0      0.29 0.01
## feature_1    103.61 0.01
## feature_2     -1.06 0.01
## feature_3     18.83 0.01
## feature_4     44.12 0.01
## feature_5      7.09 0.01
## feature_6     96.29 0.00
## feature_7     -1.26 0.02
## feature_8     -0.42 0.00
## feature_9     -0.28 0.00
## feature_10    50.94 0.00
## feature_11    -1.96 0.00
## feature_12     1.48 0.00
## feature_13    -1.30 0.00
## feature_14    -1.00 0.02
## feature_15     2.19 0.01
## labels         3.66 0.00
```
Some observations from the Summary:

* The range for feature_1,feature_3,feature_4 and feature_6 is relatively high (from 19 to 29) across the samples compared to other variables.
* The range for feature_0,feature_5,feature_11 is moderately large (from 7 to 11) across the samples compared to other variables. The value of other features varies from 0 to 3.157
* The minimum value for feature_1 to feature_6 is negative. For others, minimum value is zero.
* The mean value for feature_1 to feature_6 is very close to zero(some are negatives). For others, mean is positive.
* The median value for feature_1 to feature_6 is negatives. For others, median value is positive.
* So values of different features varie in different scales. If the data isnâ€™t normalized it will lead to a baised outcome.

## Summary Statistics and Variances: After data normalization 


```r
#Normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
```


```r
insurance <- as.data.frame(lapply(insurance1, normalize))
summary(insurance)
```

```
##    feature_0        feature_1         feature_2        feature_3      
##  Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000  
##  1st Qu.:0.1948   1st Qu.:0.09073   1st Qu.:0.2333   1st Qu.:0.02094  
##  Median :0.2727   Median :0.09501   Median :0.5000   Median :0.03640  
##  Mean   :0.2972   Mean   :0.10519   Mean   :0.4946   Mean   :0.05237  
##  3rd Qu.:0.3896   3rd Qu.:0.10596   3rd Qu.:0.6667   3rd Qu.:0.06466  
##  Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000  
##    feature_4         feature_5         feature_6         feature_7      
##  Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  
##  1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.09091  
##  Median :0.01613   Median :0.00000   Median :0.00000   Median :0.36364  
##  Mean   :0.02845   Mean   :0.04784   Mean   :0.01017   Mean   :0.39421  
##  3rd Qu.:0.03226   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.63636  
##  Max.   :1.00000   Max.   :1.00000   Max.   :1.00000   Max.   :1.00000  
##    feature_8        feature_9        feature_10        feature_11    
##  Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  
##  1st Qu.:0.5000   1st Qu.:0.3333   1st Qu.:0.00000   1st Qu.:0.0000  
##  Median :0.5000   Median :0.3333   Median :0.00000   Median :1.0000  
##  Mean   :0.5851   Mean   :0.4085   Mean   :0.01788   Mean   :0.5522  
##  3rd Qu.:1.0000   3rd Qu.:0.6667   3rd Qu.:0.00000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000  
##    feature_12      feature_13       feature_14       feature_15    
##  Min.   :0.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:0.2727   1st Qu.:1.0000  
##  Median :0.000   Median :0.0000   Median :0.5455   Median :1.0000  
##  Mean   :0.159   Mean   :0.3183   Mean   :0.5012   Mean   :0.8541  
##  3rd Qu.:0.000   3rd Qu.:1.0000   3rd Qu.:0.7273   3rd Qu.:1.0000  
##  Max.   :1.000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##      labels      
##  Min.   :0.0000  
##  1st Qu.:0.0000  
##  Median :0.0000  
##  Mean   :0.1173  
##  3rd Qu.:0.0000  
##  Max.   :1.0000
```
 
 So, all the features are normalised in the range of 0 to 1. Binary variables remain unchanged. The variance of the data after normalization is:
 

```r
sort(apply(insurance[-17], 2, sd))
```

```
##  feature_6  feature_1  feature_4  feature_3  feature_5 feature_10  feature_0 
## 0.03328427 0.03366124 0.05042517 0.05218207 0.11681114 0.13251602 0.13790212 
##  feature_9 feature_14  feature_2  feature_7  feature_8 feature_15 feature_12 
## 0.24976134 0.27306086 0.27728047 0.29756154 0.30249105 0.32889883 0.36564728 
## feature_13 feature_11 
## 0.44815779 0.49727677
```
 
So, after normaloisation, it is clear that feature_1,feature_3,feature_4,feature_6 has very low variance and feature_11 has the highest variance.

## Univariate Analysis:

### Data is imbalanced in Target Variable:


```r
p16<-ggplot(aes(x=labels), data =  insurance) +
   geom_histogram(color = I('black'), fill = "blue") +
   ggtitle('labels distribution')
p16
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

![](32312016_files/figure-html/unnamed-chunk-12-1.png)<!-- -->


Majority of the labels are zero. So, the data is heavily imbalanced

### Outliers among the features:

* Boxplot of feature_0, feature_1, feature_3, feature_4, feature_5, feature_6 are showing many outliers for higher values.
* Only feature_1 and feature_15 have outliers for lower values.


```r
par(mfrow = c(3,6)) # 6 x 2 grid
for (i in 1:(length(insurance))) {
        boxplot(insurance[,i], main = names(insurance[i]), type="l", col = 'lightblue') 
}
```

![](32312016_files/figure-html/unnamed-chunk-13-1.png)<!-- -->

It is very hard to assess the distribution observing the boxplot for many features. So let's have a look on distribution for features

### Histogram of all variables:


```r
options(repr.plot.width=15, repr.plot.height=15)
p0<-ggplot(aes(x=feature_0), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") + 
    ggtitle('feature_0 distribution')

p1<-ggplot(aes(x=feature_1), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") + 
    ggtitle('feature_1 distribution')

p2<-ggplot(aes(x=feature_2), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") + 
    ggtitle('feature_2 distribution')

p3<-ggplot(aes(x=feature_3), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") + 
    ggtitle('feature_3 distribution')

p4<-ggplot(aes(x=feature_4), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") + 
    ggtitle('feature_4 distribution')

p5<-ggplot(aes(x=feature_5), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") + 
    ggtitle('feature_5 distribution')

p6<-ggplot(aes(x=feature_6), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") +
    ggtitle('feature_6 distribution')

p7<-ggplot(aes(x=feature_7), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") +
    ggtitle('feature_7 distribution')

p8<-ggplot(aes(x=feature_8), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") +
    ggtitle('feature_8 distribution')

p9<-ggplot(aes(x=feature_9), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") +
    ggtitle('feature_8 distribution')

p10<-ggplot(aes(x=feature_10), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") +
    ggtitle('feature_10 distribution')

p11<-ggplot(aes(x=feature_11), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") +
    ggtitle('feature_11 distribution')

p12<-ggplot(aes(x=feature_12), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") +
    ggtitle('feature_12 distribution')

p13<-ggplot(aes(x=feature_13), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") +
    ggtitle('feature_13 distribution')

p14<-ggplot(aes(x=feature_14), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") +
    ggtitle('feature_14 distribution')

p15<-ggplot(aes(x=feature_15), data =  insurance) +
    geom_histogram(color = I('black'), fill = "red") +
    ggtitle('feature_15 distribution')

#p16<-ggplot(aes(x=labels), data =  insurance) +
#    geom_histogram(color = I('black'), fill = "red") +
#    ggtitle('labels distribution')

# plot all 16, 4 x 4 

grid.arrange(p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, p13, p14, p15, ncol = 4)
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

![](32312016_files/figure-html/unnamed-chunk-14-1.png)<!-- -->

* feature_0 is showing close to a uniform distribution with right skewness.
* feature_1, feature_3, feature_4,feature_5 and feature_6 are heavily right skewed.
* feature_2 distribution is multimodal. Significant number of values are negative.
* labels distribution clearly shows that only a fraction of customer will churn.

## Bivariate Analysis:

### Correlations among the features:


```r
round(cor(insurance[1:17]),3)
```

```
##            feature_0 feature_1 feature_2 feature_3 feature_4 feature_5
## feature_0      1.000     0.105    -0.006    -0.008     0.003    -0.023
## feature_1      0.105     1.000     0.005     0.016    -0.016     0.007
## feature_2     -0.006     0.005     1.000    -0.027     0.167    -0.092
## feature_3     -0.008     0.016    -0.027     1.000    -0.084     0.003
## feature_4      0.003    -0.016     0.167    -0.084     1.000    -0.092
## feature_5     -0.023     0.007    -0.092     0.003    -0.092     1.000
## feature_6     -0.001     0.026    -0.052     0.000    -0.047     0.547
## feature_7     -0.026     0.020     0.019     0.000     0.007    -0.018
## feature_8     -0.405    -0.005    -0.008     0.005    -0.006     0.018
## feature_9     -0.107     0.062     0.023     0.004     0.010     0.003
## feature_10    -0.018    -0.068     0.011    -0.012     0.020    -0.035
## feature_11    -0.182    -0.075    -0.028     0.006    -0.021     0.122
## feature_12    -0.014    -0.086     0.009    -0.003     0.000    -0.024
## feature_13     0.029    -0.030    -0.030    -0.022     0.028    -0.244
## feature_14    -0.041     0.011    -0.003     0.008    -0.110     0.032
## feature_15     0.007    -0.025     0.080     0.009     0.106    -0.855
## labels         0.016     0.051    -0.030     0.390    -0.076     0.111
##            feature_6 feature_7 feature_8 feature_9 feature_10 feature_11
## feature_0     -0.001    -0.026    -0.405    -0.107     -0.018     -0.182
## feature_1      0.026     0.020    -0.005     0.062     -0.068     -0.075
## feature_2     -0.052     0.019    -0.008     0.023      0.011     -0.028
## feature_3      0.000     0.000     0.005     0.004     -0.012      0.006
## feature_4     -0.047     0.007    -0.006     0.010      0.020     -0.021
## feature_5      0.547    -0.018     0.018     0.003     -0.035      0.122
## feature_6      1.000     0.005     0.022     0.021     -0.022      0.035
## feature_7      0.005     1.000     0.063     0.166     -0.007     -0.128
## feature_8      0.022     0.063     1.000     0.111     -0.005     -0.019
## feature_9      0.021     0.166     0.111     1.000     -0.012     -0.092
## feature_10    -0.022    -0.007    -0.005    -0.012      1.000     -0.008
## feature_11     0.035    -0.128    -0.019    -0.092     -0.008      1.000
## feature_12    -0.013    -0.035    -0.051    -0.046      0.079      0.046
## feature_13    -0.180    -0.083    -0.036    -0.113      0.019      0.190
## feature_14     0.028    -0.090    -0.004    -0.059      0.010      0.269
## feature_15    -0.596     0.008    -0.015    -0.023      0.038     -0.100
## labels         0.119     0.037     0.043     0.069     -0.024     -0.136
##            feature_12 feature_13 feature_14 feature_15 labels
## feature_0      -0.014      0.029     -0.041      0.007  0.016
## feature_1      -0.086     -0.030      0.011     -0.025  0.051
## feature_2       0.009     -0.030     -0.003      0.080 -0.030
## feature_3      -0.003     -0.022      0.008      0.009  0.390
## feature_4       0.000      0.028     -0.110      0.106 -0.076
## feature_5      -0.024     -0.244      0.032     -0.855  0.111
## feature_6      -0.013     -0.180      0.028     -0.596  0.119
## feature_7      -0.035     -0.083     -0.090      0.008  0.037
## feature_8      -0.051     -0.036     -0.004     -0.015  0.043
## feature_9      -0.046     -0.113     -0.059     -0.023  0.069
## feature_10      0.079      0.019      0.010      0.038 -0.024
## feature_11      0.046      0.190      0.269     -0.100 -0.136
## feature_12      1.000     -0.014      0.029      0.017 -0.065
## feature_13     -0.014      1.000      0.360      0.271 -0.148
## feature_14      0.029      0.360      1.000     -0.035 -0.025
## feature_15      0.017      0.271     -0.035      1.000 -0.081
## labels         -0.065     -0.148     -0.025     -0.081  1.000
```
The following features are highly corelated:
* feature 5 and feature 15 are highly corelated negatively.

The following features are moderatelyly corelated:
* feature 0 and feature 8 negatively
* feature 5 and feature 6 positively
* feature 6 and feature 15 negatively
* feature 13 and feature 14 positively

The following features are low corelated:
* feature 0 and feature 11 negatively
* feature 2 and feature 4 positively
* feature 5 and feature 13 negatively
* feature 6 and feature 13 negatively
* feature 7 and feature 9 positively
* feature 11 and feature 13 positively
* feature 11 and feature 14 positively
* feature 13 and feature 15 positively

The following features are corelated with labels:
* feature_3 positively moderate correlation
* feature_5, feature_6 low positive correlation
* feature_11, feature_13 low negative correlation

### Plot for Strongest Corelations:


```r
plot(insurance$feature_5, insurance$feature_15)
```

![](32312016_files/figure-html/unnamed-chunk-16-1.png)<!-- -->

* Very high value (=3) of feature_15 is only available when feature_5 values are relatively low(<6)
* feature_5 values are in higher range more when feature_15 values are relatively low.

### Investigating feature_3 which has strongest correlations with labels

```r
# For better analysis, labels is converted to factor type
# As feature_3 has higher correlation with labels, let's investigate the this two variables
insurance$labels <- as.factor(insurance$labels)
p4 = ggplot(aes(x=feature_3),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_3 density by labels')
p4
```

![](32312016_files/figure-html/unnamed-chunk-17-1.png)<!-- -->

It is clearly evident that data density is distributed with low spreading for feature_3 when labels value is 0 compared to 1 value.

### Investigating data spreading of all features w.r.t the classes of labels


```r
options(repr.plot.width=15, repr.plot.height=15)
p1=ggplot(aes(x=feature_0),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_0 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p2= ggplot(aes(x=feature_1),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_1 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p3 = ggplot(aes(x=feature_2),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_2 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p4 = ggplot(aes(x=feature_3),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_3 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p5 = ggplot(aes(x=feature_4),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_4 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p6 = ggplot(aes(x=feature_5),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_5 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p7 = ggplot(aes(x=feature_6),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_6 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p8 = ggplot(aes(x=feature_7),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_7 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p9 = ggplot(aes(x=feature_8),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_8 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p10 = ggplot(aes(x=feature_9),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_9 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p11 = ggplot(aes(x=feature_10),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_10 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p12 = ggplot(aes(x=feature_11),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_11 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p13 = ggplot(aes(x=feature_12),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_12 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p14 = ggplot(aes(x=feature_13),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_13 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p15 = ggplot(aes(x=feature_14),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_14 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 
p16 = ggplot(aes(x=feature_15),data =insurance) + geom_density(aes(fill = labels)) +  ggtitle('feature_15 density by labels') + theme(plot.title = element_text(size = 5, face = "bold"),axis.text=element_text(size=5), axis.title=element_text(size=5),legend.title = element_text(size = 5), 
               legend.text = element_text(size = 5)) 

grid.arrange( p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15,p16, ncol = 3)
```

![](32312016_files/figure-html/unnamed-chunk-18-1.png)<!-- -->

No feature shows specific independence in data spreading for each values of labels.

### Investigating relations among continuous features:


```r
# Now let's investigate the continuous features and labels in the data.
library(car) 
scatterplotMatrix(insurance[,c(1:7)],cex=0.2,main="Scatterplot Matrix for Insurance Data Using Floating Variables")
```

```
## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth

## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth

## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth

## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth

## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth

## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth

## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth

## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth

## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth

## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth

## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth

## Warning in smoother(x[subs], y[subs], col = smoother.args$col[i], log.x =
## FALSE, : could not fit smooth
```

![](32312016_files/figure-html/unnamed-chunk-19-1.png)<!-- -->

* Feature_3 has nonlinear negative relationship with almost all numeric features.
* Feature_1 and feature_4 has non-linear negative relationship with feature_6
* feature_1 and feature_4 relationship is also nonlinear negative.

## Multivariate EDA :

### Feature_3 data spreading for each labels and for each value of feature_15:


```r
# Feature_3 is highlighted here as it has better relationship with labels
ggplot(aes(x=feature_3),data =insurance) + geom_density(aes(fill = labels)) +
    facet_wrap(~feature_15) +
    ggtitle('Density of feature_3 with respect to feature_15 and labels')
```

![](32312016_files/figure-html/unnamed-chunk-20-1.png)<!-- -->

* From the above plot, there doesn't seem to be any specific seprability of labels considering data for feature_3 and feature_15. 
* However value 0 of labels tends to exhibit a higher feature_3 value density than value 1 of labels for all the values of feature_15. 
* Value 1 of labels tends to exhibit a spreader distribution of feature_3 value than value 1 of labels for all the values of feature_15.
* The feature_15 value of .667 exhibits a narrower spread for feature_3 value between 0 and 0.25 compared to other feature_15 values.

### Feature_3 data spreading for each labels and for each value of feature_13:


```r
ggplot(aes(x=feature_3),data =insurance) + geom_density(aes(fill = labels)) +
    facet_wrap(~feature_13) +
    ggtitle('Density of feature_3 with respect to feature_13 and labels')
```

![](32312016_files/figure-html/unnamed-chunk-21-1.png)<!-- -->

* From the above analysis plot,feature_3 shows more independence for each labels for higher value (when value is 1) of feature_13.
* However value 0 of labels tends to exhibit a higher feature_3 value density than value 1 of labels for all the values of feature_13. 
* Value 1 of labels tends to exhibit a spreader distribution of feature_3 value than value 1 of labels for all the values of feature_13.

### feature_3 values relationship with discrete variables by labels:


```r
t1=ggplot(aes(x = feature_14, y = feature_3), data = insurance) + 
    geom_point(aes(color=labels),alpha=1/4, position = 'jitter') +
    ggtitle(' Feature_3 and  feature_14 Relationship by labels')
t2= ggplot(aes(x = feature_15, y = feature_3), data = insurance) + 
    geom_point(aes(color=labels),alpha=1/4, position = 'jitter') +
    ggtitle(' Feature_3 and  feature_15 Relationship by labels')
t3 = ggplot(aes(x = feature_13, y = feature_3), data = insurance) + 
    geom_point(aes(color=labels),alpha=1/4, position = 'jitter') +
    ggtitle(' Feature_3 and  feature_13 Relationship by labels')
t4= ggplot(aes(x = feature_12, y = feature_3), data = insurance) + 
    geom_point(aes(color=labels),alpha=1/4, position = 'jitter') +
    ggtitle(' Feature_3 and  feature_12 Relationship by labels')
t5= ggplot(aes(x = feature_11, y = feature_3), data = insurance) + 
    geom_point(aes(color=labels),alpha=1/4, position = 'jitter') +
    ggtitle(' Feature_3 and  feature_11 Relationship by labels')

grid.arrange( t1,t2,t3,t4,t5, ncol = 1)
```

![](32312016_files/figure-html/unnamed-chunk-22-1.png)<!-- -->


```r
t6 =ggplot(aes(x = feature_10, y = feature_3), data = insurance) + 
    geom_point(aes(color=labels),alpha=1/4, position = 'jitter') +
    ggtitle(' Feature_3 and  feature_10 Relationship by labels')
t7= ggplot(aes(x = feature_9, y = feature_3), data = insurance) + 
    geom_point(aes(color=labels),alpha=1/4, position = 'jitter') +
    ggtitle(' Feature_3 and  feature_9 Relationship by labels')
t8= ggplot(aes(x = feature_8, y = feature_3), data = insurance) + 
    geom_point(aes(color=labels),alpha=1/4, position = 'jitter') +
    ggtitle(' Feature_3 and  feature_8 Relationship by labels')
t9= ggplot(aes(x = feature_7, y = feature_3), data = insurance) + 
    geom_point(aes(color=labels),alpha=1/4, position = 'jitter') +
    ggtitle(' Feature_3 and  feature_7 Relationship by labels')

grid.arrange( t6,t7,t8,t9, ncol = 1)
```

![](32312016_files/figure-html/unnamed-chunk-23-1.png)<!-- -->

All the plots indicate that for the same values, label 1 has higher feature_3 than the label 0 on average across all the feature values.

### Feature_3 and feature_5 relationship for each value of feature_11 by labels 

```r
ggplot(aes(x=feature_3, y=feature_5),data = insurance) + 
    geom_jitter(aes(color = labels, bg = labels), alpha=1/10,,pch=21, cex=4) +
    facet_wrap(~feature_11) +
    scale_color_brewer(type = 'div') +
    ggtitle('Feature_5 and feature_3 relationship for each classes of feature_11')
```

![](32312016_files/figure-html/unnamed-chunk-24-1.png)<!-- -->

* feature_3 value is higher for feature_5 when label is 1 for any value of feature_11.
* For label 0, feature_5 values are in higher ranges when feature_11 value is 1 

## Summary:

* The dataset is heavily biased to the value of 0 of labels.
* Feature_13 and feature_11 varies relatively more as they possess higher standard deviation.
* Only feature_5 and feature_15 has strong correlations.
* Feature_3 has the highest correlation with labels which is a moderate and positive correlation.
* Labels are weakly correlated to feature_5, feature_6, feature_11, feature_13 and feature_15.
* Data are not quite separatable by each labels for all variables.
* In case of multivariate analysis, feature_3 shows more independence among each labels only for higher value of feature_13.  
* For records with the value of 1 for labels, the feature_3 value is higher than that of labels with 0 across all the values of feature_14 and feature_15

### Key decisions obtained from EDA:

* We have observed from the graphs and statistics of exploratory data analysis that the classes (labels) are not quite separate across the data for almost all the variables. 
* So a simple linear regression will not be good enough to be an efficient classifier. 
* Here, logistic regression and KNN has been chosen as the classifier for building the model. 


# Model Development:

## Multiple Logistic Classification Model:


```r
# Creating training and validation data sets
sample_size = floor(0.8*nrow(insurance))
set.seed(777)
# randomly split data in r
splitted = sample(seq_len(nrow(insurance)),size = sample_size)
train =insurance[splitted,]
valid =insurance[-splitted,]
labels_valid=valid$labels
```

### First Logistic Model: taking all features into account:


```r
fit.glm_1 = glm(labels ~ ., data = train, family = binomial)
summary(fit.glm_1)
```

```
## 
## Call:
## glm(formula = labels ~ ., family = binomial, data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -5.5972  -0.4461  -0.2856  -0.1644   3.1657  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -4.21347    0.19644 -21.449  < 2e-16 ***
## feature_0    0.49272    0.18788   2.623  0.00873 ** 
## feature_1    1.10929    0.64321   1.725  0.08460 .  
## feature_2   -0.17919    0.09045  -1.981  0.04757 *  
## feature_3   19.32125    0.43323  44.598  < 2e-16 ***
## feature_4   -8.49653    0.91457  -9.290  < 2e-16 ***
## feature_5    3.08701    0.31479   9.807  < 2e-16 ***
## feature_6    6.07997    0.65284   9.313  < 2e-16 ***
## feature_7    0.05037    0.08580   0.587  0.55715    
## feature_8    0.44632    0.09064   4.924 8.48e-07 ***
## feature_9    0.66573    0.10061   6.617 3.68e-11 ***
## feature_10  -0.59963    0.26388  -2.272  0.02307 *  
## feature_11  -1.01122    0.05517 -18.328  < 2e-16 ***
## feature_12  -0.67303    0.08179  -8.228  < 2e-16 ***
## feature_13  -1.32451    0.07946 -16.669  < 2e-16 ***
## feature_14   0.41035    0.08911   4.605 4.12e-06 ***
## feature_15   0.79613    0.12814   6.213 5.20e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 15518  on 21699  degrees of freedom
## Residual deviance: 11470  on 21683  degrees of freedom
## AIC: 11504
## 
## Number of Fisher Scoring iterations: 6
```

```r
# Predicting model accuracy on validation data set followed by generating confusion matrix 
probs <- predict(fit.glm_1, valid, type = "response")
pred.glm_1 <- rep(0, length(probs))
pred.glm_1[probs >0.5] <- 1
confusionMatrix(table(pred.glm_1, labels_valid), labels = 1)
```

```
## Confusion Matrix and Statistics
## 
##           labels_valid
## pred.glm_1    0    1
##          0 4647  550
##          1  100  129
##                                           
##                Accuracy : 0.8802          
##                  95% CI : (0.8713, 0.8887)
##     No Information Rate : 0.8749          
##     P-Value [Acc > NIR] : 0.1207          
##                                           
##                   Kappa : 0.2359          
##                                           
##  Mcnemar's Test P-Value : <2e-16          
##                                           
##             Sensitivity : 0.9789          
##             Specificity : 0.1900          
##          Pos Pred Value : 0.8942          
##          Neg Pred Value : 0.5633          
##              Prevalence : 0.8749          
##          Detection Rate : 0.8564          
##    Detection Prevalence : 0.9578          
##       Balanced Accuracy : 0.5845          
##                                           
##        'Positive' Class : 0               
## 
```

So first logistic model accuracy on validation data set is 0.880


### Second Logistic model: with feature-selection using anova:


```r
# Selecting important features using anova
anova(fit.glm_1, test = "Chisq")
```

```
## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: labels
## 
## Terms added sequentially (first to last)
## 
## 
##            Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    
## NULL                       21699      15518              
## feature_0   1     5.81     21698      15512  0.015934 *  
## feature_1   1    33.54     21697      15478 6.968e-09 ***
## feature_2   1    19.33     21696      15459 1.099e-05 ***
## feature_3   1  2438.27     21695      13021 < 2.2e-16 ***
## feature_4   1   139.62     21694      12881 < 2.2e-16 ***
## feature_5   1   208.38     21693      12673 < 2.2e-16 ***
## feature_6   1    84.54     21692      12588 < 2.2e-16 ***
## feature_7   1    35.41     21691      12553 2.671e-09 ***
## feature_8   1    64.59     21690      12488 9.239e-16 ***
## feature_9   1    98.15     21689      12390 < 2.2e-16 ***
## feature_10  1     8.32     21688      12382  0.003916 ** 
## feature_11  1   505.82     21687      11876 < 2.2e-16 ***
## feature_12  1    64.89     21686      11811 7.929e-16 ***
## feature_13  1   282.15     21685      11529 < 2.2e-16 ***
## feature_14  1    18.45     21684      11510 1.746e-05 ***
## feature_15  1    40.38     21683      11470 2.092e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

So, feature_0, feature_1, feature_2, feature_10,feature_14 can be removed from the model as the drop of deviance is relatively small (<35).


```r
fit.glm_2 = glm(labels ~ .-feature_0-feature_1-feature_2-feature_10-feature_14, data = train, family = binomial)

summary(fit.glm_2)
```

```
## 
## Call:
## glm(formula = labels ~ . - feature_0 - feature_1 - feature_2 - 
##     feature_10 - feature_14, family = binomial, data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -5.5425  -0.4500  -0.2865  -0.1654   3.2156  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -3.73492    0.15017 -24.871  < 2e-16 ***
## feature_3   19.33326    0.43280  44.670  < 2e-16 ***
## feature_4   -9.28430    0.90753 -10.230  < 2e-16 ***
## feature_5    3.12046    0.31434   9.927  < 2e-16 ***
## feature_6    6.19607    0.65497   9.460  < 2e-16 ***
## feature_7    0.03599    0.08536   0.422    0.673    
## feature_8    0.34419    0.08088   4.255 2.09e-05 ***
## feature_9    0.65190    0.10028   6.501 8.00e-11 ***
## feature_11  -1.01118    0.05345 -18.917  < 2e-16 ***
## feature_12  -0.69507    0.08119  -8.561  < 2e-16 ***
## feature_13  -1.22277    0.07697 -15.886  < 2e-16 ***
## feature_15   0.74782    0.12798   5.843 5.12e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 15518  on 21699  degrees of freedom
## Residual deviance: 11513  on 21688  degrees of freedom
## AIC: 11537
## 
## Number of Fisher Scoring iterations: 6
```


```r
probs <- predict(fit.glm_2, valid, type = "response")
pred.glm_2 <- rep(0, length(probs))
pred.glm_2[probs >0.5] <- 1
confusionMatrix(table(pred.glm_2, labels_valid), labels = 1)
```

```
## Confusion Matrix and Statistics
## 
##           labels_valid
## pred.glm_2    0    1
##          0 4654  558
##          1   93  121
##                                           
##                Accuracy : 0.88            
##                  95% CI : (0.8711, 0.8886)
##     No Information Rate : 0.8749          
##     P-Value [Acc > NIR] : 0.1293          
##                                           
##                   Kappa : 0.2245          
##                                           
##  Mcnemar's Test P-Value : <2e-16          
##                                           
##             Sensitivity : 0.9804          
##             Specificity : 0.1782          
##          Pos Pred Value : 0.8929          
##          Neg Pred Value : 0.5654          
##              Prevalence : 0.8749          
##          Detection Rate : 0.8577          
##    Detection Prevalence : 0.9606          
##       Balanced Accuracy : 0.5793          
##                                           
##        'Positive' Class : 0               
## 
```


* So, model accuracy remains same (0.880) and precision decreased slightly. However, model complexity is reduced significantly.

### Third Logistic model: Further feature reduction based on Z-static:

* We know that a bigger Z static(both positive and negative) indicates that the corresponding true regression coefficient is not 0 and the corresponding X-variable matters. 
* So, here, we can remove the feature_7 and feature_8 from the second model as they showed relatively small z value(-5>Z>5) (see output at line 481: summary statistics of second model )
* In that case, only feature_0,feature_1,feature_2,feature_7,feature_8,feature_10,feature_14 shall remain in the third logistic model


```r
fit.glm_3 = glm(labels ~ .-feature_0-feature_1-feature_2-feature_7-feature_8-feature_10-feature_14, data = train, family = binomial)
summary(fit.glm_3)
```

```
## 
## Call:
## glm(formula = labels ~ . - feature_0 - feature_1 - feature_2 - 
##     feature_7 - feature_8 - feature_10 - feature_14, family = binomial, 
##     data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -5.5424  -0.4513  -0.2885  -0.1658   3.1677  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -3.53293    0.13992 -25.249  < 2e-16 ***
## feature_3   19.29828    0.43226  44.645  < 2e-16 ***
## feature_4   -9.40972    0.90931 -10.348  < 2e-16 ***
## feature_5    3.12930    0.31453   9.949  < 2e-16 ***
## feature_6    6.24633    0.65151   9.588  < 2e-16 ***
## feature_9    0.70477    0.09872   7.139 9.39e-13 ***
## feature_11  -1.01429    0.05313 -19.092  < 2e-16 ***
## feature_12  -0.70364    0.08107  -8.680  < 2e-16 ***
## feature_13  -1.23310    0.07683 -16.050  < 2e-16 ***
## feature_15   0.75495    0.12794   5.901 3.62e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 15518  on 21699  degrees of freedom
## Residual deviance: 11531  on 21690  degrees of freedom
## AIC: 11551
## 
## Number of Fisher Scoring iterations: 6
```

```r
probs <- predict(fit.glm_3, valid, type = "response")
pred.glm_3 <- rep(0, length(probs))
pred.glm_3[probs >0.5] <- 1
confusionMatrix(table(pred.glm_3, labels_valid), labels = 1)
```

```
## Confusion Matrix and Statistics
## 
##           labels_valid
## pred.glm_3    0    1
##          0 4652  556
##          1   95  123
##                                           
##                Accuracy : 0.88            
##                  95% CI : (0.8711, 0.8886)
##     No Information Rate : 0.8749          
##     P-Value [Acc > NIR] : 0.1293          
##                                           
##                   Kappa : 0.2272          
##                                           
##  Mcnemar's Test P-Value : <2e-16          
##                                           
##             Sensitivity : 0.9800          
##             Specificity : 0.1811          
##          Pos Pred Value : 0.8932          
##          Neg Pred Value : 0.5642          
##              Prevalence : 0.8749          
##          Detection Rate : 0.8574          
##    Detection Prevalence : 0.9598          
##       Balanced Accuracy : 0.5806          
##                                           
##        'Positive' Class : 0               
## 
```

```r
with(fit.glm_3, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
```

```
## [1] 0
```

* So, model performance did not change at all. The number of model predictors are decreased. The above R-chunk proves that third logistic model varies significantly than null model.

### Fourth Multiple Logistic Model: Feature selected from EDA:

From EDA, we see that feature_3,feature_5,feature_6,feature_11, feature_13, feature_15 have better correlations with labels.


```r
set.seed(3)
fit.glm_4 = glm(labels ~ feature_3 +feature_5+feature_6+feature_11+feature_13+ feature_15 , data = train, family = binomial)
summary(fit.glm_4)
```

```
## 
## Call:
## glm(formula = labels ~ feature_3 + feature_5 + feature_6 + feature_11 + 
##     feature_13 + feature_15, family = binomial, data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -5.4136  -0.4503  -0.3003  -0.1802   3.0707  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -3.38483    0.13007 -26.023  < 2e-16 ***
## feature_3   19.06929    0.42367  45.009  < 2e-16 ***
## feature_5    3.18494    0.31491  10.114  < 2e-16 ***
## feature_6    5.75505    0.63756   9.027  < 2e-16 ***
## feature_11  -1.05011    0.05268 -19.933  < 2e-16 ***
## feature_13  -1.23905    0.07642 -16.214  < 2e-16 ***
## feature_15   0.63870    0.12792   4.993 5.95e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 15518  on 21699  degrees of freedom
## Residual deviance: 11816  on 21693  degrees of freedom
## AIC: 11830
## 
## Number of Fisher Scoring iterations: 6
```


```r
probs <- predict(fit.glm_4, valid, type = "response")
pred.glm_4 <- rep(0, length(probs))
pred.glm_4[probs >0.5] <- 1
confusionMatrix(table(pred.glm_4, labels_valid), labels = 1)
```

```
## Confusion Matrix and Statistics
## 
##           labels_valid
## pred.glm_4    0    1
##          0 4664  565
##          1   83  114
##                                           
##                Accuracy : 0.8806          
##                  95% CI : (0.8716, 0.8891)
##     No Information Rate : 0.8749          
##     P-Value [Acc > NIR] : 0.1048          
##                                           
##                   Kappa : 0.2162          
##                                           
##  Mcnemar's Test P-Value : <2e-16          
##                                           
##             Sensitivity : 0.9825          
##             Specificity : 0.1679          
##          Pos Pred Value : 0.8919          
##          Neg Pred Value : 0.5787          
##              Prevalence : 0.8749          
##          Detection Rate : 0.8596          
##    Detection Prevalence : 0.9637          
##       Balanced Accuracy : 0.5752          
##                                           
##        'Positive' Class : 0               
## 
```


* Though the model accuracy remains almost same,precision is reduced significantly.

* Considering the above 4 logistic models, model-3 is preferable as it has less model complexity (9 predictors) and 

* Model accuracy and precision is almost same to that of best accuracy shown model,i.e model-1. Following table confirms that:

|        Model_Name          |  Evaluation_Technique    |Accuracy   |   Model Complexity    | Specificity |
|----------------------------|--------------------------|---------- |-----------------------|-------------|
|Logistic Regression-model-1 | Validation set approach  | 0.8802    | Most (All features)   | 0.1911      |
|Logistic Regression-model-2 | Validation set approach  | 0.8800    | Moderate (11 features)| 0.1782      |
|Logistic Regression-model-3 | Validation set approach  | 0.8800    | Moderate (9 features) | 0.1811      |
|Logistic Regression-model-4 | Validation set approach  | 0.8806    | Moderate (6 features) | 0.1679      |



### Cross-checking Selected logistic model performance on whole training set:


```r
insurance.labels<-insurance$labels
probs <- predict(fit.glm_3, insurance, type = "response")
pred.glm_final <- rep(0, length(probs))
pred.glm_final[probs >0.5] <- 1
confusionMatrix(table(pred.glm_final, insurance.labels), labels = 1)
```

```
## Confusion Matrix and Statistics
## 
##               insurance.labels
## pred.glm_final     0     1
##              0 23472  2530
##              1   472   652
##                                          
##                Accuracy : 0.8893         
##                  95% CI : (0.8855, 0.893)
##     No Information Rate : 0.8827         
##     P-Value [Acc > NIR] : 0.0003215      
##                                          
##                   Kappa : 0.2574         
##                                          
##  Mcnemar's Test P-Value : < 2.2e-16      
##                                          
##             Sensitivity : 0.9803         
##             Specificity : 0.2049         
##          Pos Pred Value : 0.9027         
##          Neg Pred Value : 0.5801         
##              Prevalence : 0.8827         
##          Detection Rate : 0.8653         
##    Detection Prevalence : 0.9586         
##       Balanced Accuracy : 0.5926         
##                                          
##        'Positive' Class : 0              
## 
```

* So model accuracy is 0.889. That means, chosen logistic model performance is quite consistent among validation and whole training data set. Now let's check another classifier for having better model.


## K-Nearest Neighbour(KNN) Classification:

### First KNN model: considering all features of the data-set:


```r
library(class)
```



```r
set.seed (1)
knn.pred1 <- knn(train[,-17], valid[,-17], train$labels , k = 3)
confusionMatrix(table(knn.pred1, valid$labels), labels = 1)
```

```
## Confusion Matrix and Statistics
## 
##          
## knn.pred1    0    1
##         0 4600  516
##         1  147  163
##                                           
##                Accuracy : 0.8778          
##                  95% CI : (0.8688, 0.8864)
##     No Information Rate : 0.8749          
##     P-Value [Acc > NIR] : 0.2634          
##                                           
##                   Kappa : 0.2726          
##                                           
##  Mcnemar's Test P-Value : <2e-16          
##                                           
##             Sensitivity : 0.9690          
##             Specificity : 0.2401          
##          Pos Pred Value : 0.8991          
##          Neg Pred Value : 0.5258          
##              Prevalence : 0.8749          
##          Detection Rate : 0.8478          
##    Detection Prevalence : 0.9429          
##       Balanced Accuracy : 0.6045          
##                                           
##        'Positive' Class : 0               
## 
```

So, KNN model-1 accuracy is 0.878

### Second KNN Model: Considering only the chosen features of ultimately selected logistic model:


```r
train.x <- train[,c("feature_3","feature_4","feature_5","feature_6","feature_9","feature_11","feature_12","feature_13","feature_15")]
valid.x <- valid[,c("feature_3","feature_4","feature_5","feature_6","feature_9","feature_11","feature_12","feature_13","feature_15")]
```


```r
set.seed (1)
knn.pred2 <- knn(train.x, valid.x, train$labels , k = 3)
confusionMatrix(table(knn.pred2, valid$labels), labels = 1)
```

```
## Confusion Matrix and Statistics
## 
##          
## knn.pred2    0    1
##         0 4495  434
##         1  252  245
##                                           
##                Accuracy : 0.8736          
##                  95% CI : (0.8644, 0.8823)
##     No Information Rate : 0.8749          
##     P-Value [Acc > NIR] : 0.6226          
##                                           
##                   Kappa : 0.3477          
##                                           
##  Mcnemar's Test P-Value : 4.826e-12       
##                                           
##             Sensitivity : 0.9469          
##             Specificity : 0.3608          
##          Pos Pred Value : 0.9119          
##          Neg Pred Value : 0.4930          
##              Prevalence : 0.8749          
##          Detection Rate : 0.8284          
##    Detection Prevalence : 0.9084          
##       Balanced Accuracy : 0.6539          
##                                           
##        'Positive' Class : 0               
## 
```

So, KNN model-2 accuracy : 0.874

Now selecting appropriate K hyper-parameter:


```r
i=1
k.optm=1
for (i in 1:20){
 knn.mod <- knn(train.x,valid.x,train$labels, k=i)
 k.optm[i] <- 100 * sum(valid$labels == knn.mod)/NROW(valid$labels)
 k=i
 cat('for K ',k,':',k.optm[i],';')
}
```

```
## for K  1 : 85.97494 ;for K  2 : 86.47254 ;for K  3 : 87.24659 ;for K  4 : 87.63362 ;for K  5 : 88.16808 ;for K  6 : 88.31552 ;for K  7 : 88.49982 ;for K  8 : 88.66568 ;for K  9 : 88.77626 ;for K  10 : 88.75783 ;for K  11 : 88.94213 ;for K  12 : 88.84998 ;for K  13 : 88.90527 ;for K  14 : 88.68411 ;for K  15 : 88.81312 ;for K  16 : 89.05271 ;for K  17 : 88.9237 ;for K  18 : 88.9237 ;for K  19 : 88.94213 ;for K  20 : 88.96056 ;
```

* In this case, we can select K=10.
* Comparing both models of KNN, based on validation set method, model1 performs better than model2.
* p-value of both KNN model is also very low which justifies the statistical significance of the models.
* However, the variation in model accuracy might be the result of how the data is splitted. So, use of another validation technique for cross checking is important. 
* For cross-checking model-performance, K-fold cross validation technique can be used which will nullify the impact of data-splitting which is available in validation-set technique.

### Cross-checking KNN model performance using K-fold cross validation technique: selection of ultimate KNN model

#### K-Fold cross validation on KNN Model-1


```r
library(caret)
library(class)
folds = createFolds(insurance$labels, k = 10)
cv = lapply(folds, function(x) {
  training_fold = insurance[-x,]
  test_fold = insurance[x, ]
  y_pred = knn( training_fold[,-17], test_fold[,-17], training_fold[,17] , k = 10)
  #classifier = KNN(formula = Purchased ~ .,data = training_fold,type = 'C-classification', kernel = 'radial')
  #y_pred = predict(classifier, newdata = test_fold[-17])
  cm = table(test_fold[, 17], y_pred)
  accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
  return(accuracy)
})
accuracy = mean(as.numeric(cv))
accuracy
```

```
## [1] 0.8883728
```


#### K-Fold cross validation on KNN Model-2:


```r
library(caret)
library(class)
folds = createFolds(insurance$labels, k = 10)
cv = lapply(folds, function(x) {
  training_fold = insurance[-x,c("feature_3","feature_4","feature_5","feature_6","feature_9","feature_11","feature_12","feature_13","feature_15","labels") ]
  test_fold = insurance[x,c("feature_3","feature_4","feature_5","feature_6","feature_9","feature_11","feature_12","feature_13","feature_15","labels") ]
  y_pred = knn( training_fold[,-10], test_fold[,-10], training_fold[,10] , k = 10)
  #classifier = KNN(formula = Purchased ~ .,data = training_fold,type = 'C-classification', kernel = 'radial')
  #y_pred = predict(classifier, newdata = test_fold[-17])
  cm = table(test_fold[, 10], y_pred)
  accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
  return(accuracy)
})
accuracy = mean(as.numeric(cv))
accuracy
```

```
## [1] 0.8950097
```
* So, K-fold cross-validation ensures better accuracy of KNN model-2. And this result is more reliable compared to validation data set technique.

Now, it is time to compare all KNN model accuracy:

|Model_Name         |       Evaluation_Technique        |Accuracy  | Model Complexity     |
|-------------------|-----------------------------------|----------|----------------------|
|KNN-model-1        | Validation set approach           | 0.8778   | Most (All features)  |
|KNN-model-2        | Validation set approach           | 0.8736   | Moderate (9 features)|
|KNN-model-1        | K-fold cross validation approach  | 0.8878   | Most (All features)  |
|KNN-model-2        | K-fold cross validation approach  | 0.8943   | Moderate (9 features)|

So, selected KNN model is KNN model-2

#### Crosschecking KNN model-2 performance using whole training data set (here it is 'insurance' data)


```r
set.seed (1)
knn.pred0 <- knn(train.x, insurance[,c("feature_3","feature_4","feature_5","feature_6","feature_9","feature_11","feature_12","feature_13","feature_15")], train$labels , k = 10)
confusionMatrix(table(knn.pred0, insurance$labels), labels = 1)
```

```
## Confusion Matrix and Statistics
## 
##          
## knn.pred0     0     1
##         0 23308  1926
##         1   636  1256
##                                         
##                Accuracy : 0.9056        
##                  95% CI : (0.902, 0.909)
##     No Information Rate : 0.8827        
##     P-Value [Acc > NIR] : < 2.2e-16     
##                                         
##                   Kappa : 0.4467        
##                                         
##  Mcnemar's Test P-Value : < 2.2e-16     
##                                         
##             Sensitivity : 0.9734        
##             Specificity : 0.3947        
##          Pos Pred Value : 0.9237        
##          Neg Pred Value : 0.6638        
##              Prevalence : 0.8827        
##          Detection Rate : 0.8592        
##    Detection Prevalence : 0.9303        
##       Balanced Accuracy : 0.6841        
##                                         
##        'Positive' Class : 0             
## 
```
So, the validation of KNN model on whole training set provides better accuracy as it is expected; because maximum fraction of whole insurance data were used for training the model. 


# Model Evaluation Based on Test Data

We already performed K-fold cross validation 
